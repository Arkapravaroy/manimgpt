{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97tbE40sMoSr",
        "outputId": "54098ab5-c9a4-4c33-9829-e2fd5c688998"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset generated with 644 samples\n",
            "Categories distribution:\n",
            "  basic_shapes: 10 samples\n",
            "  text_animation: 8 samples\n",
            "  math_expressions: 7 samples\n",
            "  movement: 600 samples\n",
            "  rotation: 5 samples\n",
            "  scaling: 4 samples\n",
            "  graphs: 5 samples\n",
            "  transformations: 5 samples\n",
            "\n",
            "Dataset saved as 'manim_scene_dataset.json'\n",
            "Sample structure:\n",
            "{\n",
            "  \"id\": 1,\n",
            "  \"description\": \"A blue rectangle 2.4x1.3 units draws itself\",\n",
            "  \"duration\": \"1-2 seconds\",\n",
            "  \"category\": \"basic_shapes\",\n",
            "  \"manim_code\": \"from manim import *\\n\\nclass Scene1(Scene):\\n    def construct(self):\\n        rect = Rectangle(width=2.4, height=1.3).set_color(BLUE)\\n        self.play(ShowCreation(rect))\\n        self.wait(1)\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import random\n",
        "import math\n",
        "\n",
        "def generate_manim_dataset():\n",
        "    \"\"\"Generate a comprehensive dataset of scene descriptions and corresponding Manim code\"\"\"\n",
        "\n",
        "    dataset = []\n",
        "\n",
        "    # 1. Basic Shape Animations (100 samples)\n",
        "    shapes = ['Circle', 'Square', 'Triangle', 'Rectangle', 'Polygon']\n",
        "    colors = ['RED', 'BLUE', 'GREEN', 'YELLOW', 'PURPLE', 'ORANGE', 'PINK', 'CYAN']\n",
        "    animations = ['FadeIn', 'DrawBorderThenFill', 'Create', 'ShowCreation', 'Write']\n",
        "\n",
        "    for i in range(10):\n",
        "        shape = random.choice(shapes)\n",
        "        color = random.choice(colors)\n",
        "        animation = random.choice(animations)\n",
        "\n",
        "        # Initialize description and code variables\n",
        "        description = \"\"\n",
        "        code = \"\"\n",
        "\n",
        "        if shape == 'Circle':\n",
        "            radius = round(random.uniform(0.5, 2.0), 1)\n",
        "            description = f\"A {color.lower()} circle with radius {radius} appears on screen\"\n",
        "            code = f\"\"\"from manim import *\n",
        "\n",
        "class Scene{i+1}(Scene):\n",
        "    def construct(self):\n",
        "        circle = Circle(radius={radius}).set_color({color})\n",
        "        self.play({animation}(circle))\n",
        "        self.wait(1)\"\"\"\n",
        "\n",
        "        elif shape == 'Square':\n",
        "            side = round(random.uniform(1.0, 3.0), 1)\n",
        "            description = f\"A {color.lower()} square with side length {side} materializes\"\n",
        "            code = f\"\"\"from manim import *\n",
        "\n",
        "class Scene{i+1}(Scene):\n",
        "    def construct(self):\n",
        "        square = Square(side_length={side}).set_color({color})\n",
        "        self.play({animation}(square))\n",
        "        self.wait(1)\"\"\"\n",
        "\n",
        "        elif shape == 'Rectangle':\n",
        "            width = round(random.uniform(2.0, 4.0), 1)\n",
        "            height = round(random.uniform(1.0, 2.5), 1)\n",
        "            description = f\"A {color.lower()} rectangle {width}x{height} units draws itself\"\n",
        "            code = f\"\"\"from manim import *\n",
        "\n",
        "class Scene{i+1}(Scene):\n",
        "    def construct(self):\n",
        "        rect = Rectangle(width={width}, height={height}).set_color({color})\n",
        "        self.play({animation}(rect))\n",
        "        self.wait(1)\"\"\"\n",
        "\n",
        "        elif shape == 'Triangle':\n",
        "            description = f\"A {color.lower()} triangle appears with animation\"\n",
        "            code = f\"\"\"from manim import *\n",
        "\n",
        "class Scene{i+1}(Scene):\n",
        "    def construct(self):\n",
        "        triangle = Triangle().set_color({color})\n",
        "        self.play({animation}(triangle))\n",
        "        self.wait(1)\"\"\"\n",
        "\n",
        "        elif shape == 'Polygon':\n",
        "            sides = random.choice([5, 6, 8])\n",
        "            description = f\"A {color.lower()} {sides}-sided polygon appears on screen\"\n",
        "            code = f\"\"\"from manim import *\n",
        "\n",
        "class Scene{i+1}(Scene):\n",
        "    def construct(self):\n",
        "        polygon = RegularPolygon(n={sides}).set_color({color})\n",
        "        self.play({animation}(polygon))\n",
        "        self.wait(1)\"\"\"\n",
        "\n",
        "        dataset.append({\n",
        "            \"id\": i+1,\n",
        "            \"description\": description,\n",
        "            \"duration\": \"1-2 seconds\",\n",
        "            \"category\": \"basic_shapes\",\n",
        "            \"manim_code\": code\n",
        "        })\n",
        "\n",
        "    # 2. Text Animations (80 samples)\n",
        "    text_samples = [\n",
        "        \"Hello World\", \"Mathematics\", \"Physics\", \"Chemistry\", \"Biology\",\n",
        "        \"Welcome\", \"Python\", \"Manim\", \"Animation\", \"Science\",\n",
        "        \"Learning\", \"Education\", \"Teaching\", \"Students\", \"Knowledge\"\n",
        "    ]\n",
        "\n",
        "    for i in range(8):\n",
        "        text = random.choice(text_samples)\n",
        "        color = random.choice(colors)\n",
        "        font_size = random.choice([24, 36, 48, 60])\n",
        "\n",
        "        description = f\"The text '{text}' appears in {color.lower()} color\"\n",
        "        code = f\"\"\"from manim import *\n",
        "\n",
        "class Scene{i+101}(Scene):\n",
        "    def construct(self):\n",
        "        text = Text(\"{text}\", font_size={font_size}).set_color({color})\n",
        "        self.play(Write(text))\n",
        "        self.wait(1)\"\"\"\n",
        "\n",
        "        dataset.append({\n",
        "            \"id\": i+101,\n",
        "            \"description\": description,\n",
        "            \"duration\": \"1-2 seconds\",\n",
        "            \"category\": \"text_animation\",\n",
        "            \"manim_code\": code\n",
        "        })\n",
        "\n",
        "    # 3. Mathematical Expressions (70 samples)\n",
        "    expressions = [\n",
        "        \"x^2 + y^2 = r^2\", \"E = mc^2\", \"a^2 + b^2 = c^2\",\n",
        "        \"\\\\frac{d}{dx}x^2 = 2x\", \"\\\\int x dx = \\\\frac{x^2}{2}\",\n",
        "        \"\\\\sin^2(x) + \\\\cos^2(x) = 1\", \"F = ma\", \"PV = nRT\"\n",
        "    ]\n",
        "\n",
        "    for i in range(7):\n",
        "        expr = random.choice(expressions)\n",
        "        color = random.choice(colors)\n",
        "\n",
        "        description = f\"Mathematical equation '{expr}' is written on screen\"\n",
        "        code = f\"\"\"from manim import *\n",
        "\n",
        "class Scene{i+181}(Scene):\n",
        "    def construct(self):\n",
        "        equation = MathTex(r\"{expr}\").set_color({color})\n",
        "        self.play(Write(equation))\n",
        "        self.wait(1)\"\"\"\n",
        "\n",
        "        dataset.append({\n",
        "            \"id\": i+181,\n",
        "            \"description\": description,\n",
        "            \"duration\": \"1-2 seconds\",\n",
        "            \"category\": \"math_expressions\",\n",
        "            \"manim_code\": code\n",
        "        })\n",
        "\n",
        "    # 4. Movement Animations (60 samples)\n",
        "    directions = ['LEFT', 'RIGHT', 'UP', 'DOWN']\n",
        "\n",
        "    for i in range(600):\n",
        "        shape = random.choice(['Circle', 'Square'])\n",
        "        color = random.choice(colors)\n",
        "        direction = random.choice(directions)\n",
        "        distance = round(random.uniform(1.0, 3.0), 1)\n",
        "\n",
        "        description = f\"A {color.lower()} {shape.lower()} moves {direction.lower()} by {distance} units\"\n",
        "\n",
        "        if shape == 'Circle':\n",
        "            code = f\"\"\"from manim import *\n",
        "\n",
        "class Scene{i+251}(Scene):\n",
        "    def construct(self):\n",
        "        circle = Circle().set_color({color})\n",
        "        self.play(Create(circle))\n",
        "        self.play(circle.animate.shift({direction} * {distance}))\n",
        "        self.wait(0.5)\"\"\"\n",
        "        else:\n",
        "            code = f\"\"\"from manim import *\n",
        "\n",
        "class Scene{i+251}(Scene):\n",
        "    def construct(self):\n",
        "        square = Square().set_color({color})\n",
        "        self.play(Create(square))\n",
        "        self.play(square.animate.shift({direction} * {distance}))\n",
        "        self.wait(0.5)\"\"\"\n",
        "\n",
        "        dataset.append({\n",
        "            \"id\": i+251,\n",
        "            \"description\": description,\n",
        "            \"duration\": \"1-2 seconds\",\n",
        "            \"category\": \"movement\",\n",
        "            \"manim_code\": code\n",
        "        })\n",
        "\n",
        "    # 5. Rotation Animations (50 samples)\n",
        "    for i in range(5):\n",
        "        shape = random.choice(['Square', 'Rectangle', 'Triangle'])\n",
        "        color = random.choice(colors)\n",
        "        angle = random.choice([45, 90, 180, 270, 360])\n",
        "\n",
        "        description = f\"A {color.lower()} {shape.lower()} rotates {angle} degrees\"\n",
        "\n",
        "        if shape == 'Square':\n",
        "            code = f\"\"\"from manim import *\n",
        "\n",
        "class Scene{i+311}(Scene):\n",
        "    def construct(self):\n",
        "        square = Square().set_color({color})\n",
        "        self.play(Create(square))\n",
        "        self.play(Rotate(square, {angle}*DEGREES))\n",
        "        self.wait(0.5)\"\"\"\n",
        "        elif shape == 'Rectangle':\n",
        "            code = f\"\"\"from manim import *\n",
        "\n",
        "class Scene{i+311}(Scene):\n",
        "    def construct(self):\n",
        "        rect = Rectangle().set_color({color})\n",
        "        self.play(Create(rect))\n",
        "        self.play(Rotate(rect, {angle}*DEGREES))\n",
        "        self.wait(0.5)\"\"\"\n",
        "        else:  # Triangle\n",
        "            code = f\"\"\"from manim import *\n",
        "\n",
        "class Scene{i+311}(Scene):\n",
        "    def construct(self):\n",
        "        triangle = Triangle().set_color({color})\n",
        "        self.play(Create(triangle))\n",
        "        self.play(Rotate(triangle, {angle}*DEGREES))\n",
        "        self.wait(0.5)\"\"\"\n",
        "\n",
        "        dataset.append({\n",
        "            \"id\": i+311,\n",
        "            \"description\": description,\n",
        "            \"duration\": \"1-2 seconds\",\n",
        "            \"category\": \"rotation\",\n",
        "            \"manim_code\": code\n",
        "        })\n",
        "\n",
        "    # 6. Scaling Animations (40 samples)\n",
        "    for i in range(4):\n",
        "        shape = random.choice(['Circle', 'Square'])\n",
        "        color = random.choice(colors)\n",
        "        scale_factor = round(random.uniform(0.5, 2.5), 1)\n",
        "\n",
        "        description = f\"A {color.lower()} {shape.lower()} scales by factor {scale_factor}\"\n",
        "\n",
        "        if shape == 'Circle':\n",
        "            code = f\"\"\"from manim import *\n",
        "\n",
        "class Scene{i+361}(Scene):\n",
        "    def construct(self):\n",
        "        circle = Circle().set_color({color})\n",
        "        self.play(Create(circle))\n",
        "        self.play(circle.animate.scale({scale_factor}))\n",
        "        self.wait(0.5)\"\"\"\n",
        "        else:\n",
        "            code = f\"\"\"from manim import *\n",
        "\n",
        "class Scene{i+361}(Scene):\n",
        "    def construct(self):\n",
        "        square = Square().set_color({color})\n",
        "        self.play(Create(square))\n",
        "        self.play(square.animate.scale({scale_factor}))\n",
        "        self.wait(0.5)\"\"\"\n",
        "\n",
        "        dataset.append({\n",
        "            \"id\": i+361,\n",
        "            \"description\": description,\n",
        "            \"duration\": \"1-2 seconds\",\n",
        "            \"category\": \"scaling\",\n",
        "            \"manim_code\": code\n",
        "        })\n",
        "\n",
        "    # 7. Graph and Function Plotting (50 samples)\n",
        "    functions = [\n",
        "        (\"x^2\", \"x**2\", \"parabola\"),\n",
        "        (\"sin(x)\", \"np.sin(x)\", \"sine wave\"),\n",
        "        (\"cos(x)\", \"np.cos(x)\", \"cosine wave\"),\n",
        "        (\"x^3\", \"x**3\", \"cubic function\"),\n",
        "        (\"e^x\", \"np.exp(x)\", \"exponential function\")\n",
        "    ]\n",
        "\n",
        "    for i in range(5):\n",
        "        func_tex, func_code, func_name = random.choice(functions)\n",
        "        color = random.choice(colors)\n",
        "\n",
        "        description = f\"A {color.lower()} graph of {func_name} {func_tex} appears\"\n",
        "        code = f\"\"\"from manim import *\n",
        "import numpy as np\n",
        "\n",
        "class Scene{i+401}(Scene):\n",
        "    def construct(self):\n",
        "        axes = Axes(x_range=[-3, 3], y_range=[-3, 3])\n",
        "        graph = axes.plot(lambda x: {func_code}, color={color})\n",
        "        self.play(Create(axes))\n",
        "        self.play(Create(graph))\n",
        "        self.wait(1)\"\"\"\n",
        "\n",
        "        dataset.append({\n",
        "            \"id\": i+401,\n",
        "            \"description\": description,\n",
        "            \"duration\": \"2 seconds\",\n",
        "            \"category\": \"graphs\",\n",
        "            \"manim_code\": code\n",
        "        })\n",
        "\n",
        "    # 8. Transformation Animations (50 samples)\n",
        "    transformations = [\n",
        "        (\"Circle\", \"Square\", \"circle transforms into square\"),\n",
        "        (\"Square\", \"Triangle\", \"square morphs into triangle\"),\n",
        "        (\"Triangle\", \"Circle\", \"triangle becomes circle\"),\n",
        "        (\"Rectangle\", \"Circle\", \"rectangle transforms to circle\")\n",
        "    ]\n",
        "\n",
        "    for i in range(5):\n",
        "        shape1, shape2, description_text = random.choice(transformations)\n",
        "        color = random.choice(colors)\n",
        "\n",
        "        description = f\"A {color.lower()} {description_text}\"\n",
        "        code = f\"\"\"from manim import *\n",
        "\n",
        "class Scene{i+451}(Scene):\n",
        "    def construct(self):\n",
        "        shape1 = {shape1}().set_color({color})\n",
        "        shape2 = {shape2}().set_color({color})\n",
        "        self.play(Create(shape1))\n",
        "        self.play(Transform(shape1, shape2))\n",
        "        self.wait(1)\"\"\"\n",
        "\n",
        "        dataset.append({\n",
        "            \"id\": i+451,\n",
        "            \"description\": description,\n",
        "            \"duration\": \"2 seconds\",\n",
        "            \"category\": \"transformations\",\n",
        "            \"manim_code\": code\n",
        "        })\n",
        "\n",
        "    return dataset\n",
        "\n",
        "# Generate the dataset\n",
        "dataset = generate_manim_dataset()\n",
        "\n",
        "# Save as JSON file\n",
        "with open('manim_scene_dataset.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(dataset, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(f\"Dataset generated with {len(dataset)} samples\")\n",
        "print(\"Categories distribution:\")\n",
        "categories = {}\n",
        "for item in dataset:\n",
        "    cat = item['category']\n",
        "    categories[cat] = categories.get(cat, 0) + 1\n",
        "\n",
        "for cat, count in categories.items():\n",
        "    print(f\"  {cat}: {count} samples\")\n",
        "\n",
        "print(\"\\nDataset saved as 'manim_scene_dataset.json'\")\n",
        "print(\"Sample structure:\")\n",
        "print(json.dumps(dataset[0], indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import random\n",
        "import math\n",
        "import torch\n",
        "import tiktoken\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "class DataCreation():\n",
        "    def __init__(self):\n",
        "        self.DataList = json.load(open(r\"manim_scene_dataset.json\"))\n",
        "\n",
        "        pass\n",
        "    def converting_to_continuous_Text(self):\n",
        "        data_list = self.DataList\n",
        "        formatted_list = []\n",
        "        for unformatted_data_item in data_list:\n",
        "\n",
        "            formatted_list.append( \"for visualization of the scene with description: \" + unformatted_data_item['description']\\\n",
        "                + \"and duration: \"+ str(unformatted_data_item['duration']) + \", python and manim based code is the follwoing:\\n\" \\\n",
        "                    + unformatted_data_item['manim_code'])\n",
        "\n",
        "        return formatted_list\n",
        "    def verify_formatting(self):\n",
        "        data_list = self.DataList\n",
        "        unformatted_data_item = data_list[0]\n",
        "        formatted_item = \"for visualization of the scene with description: \" + unformatted_data_item['description']\\\n",
        "                + \"and duration: \"+ str(unformatted_data_item['duration']) + \", python and manim based code is the follwoing:\\n\" \\\n",
        "                    + unformatted_data_item['manim_code']\n",
        "\n",
        "        return formatted_item\n",
        "    def save_formatted_data(self, formatted_data_list):\n",
        "        json.dump(formatted_data_list, open(r\"formatted_manim_scene_dataset.json\", \"w\"))\n",
        "\n",
        "class LMDataset(Dataset):\n",
        "    def __init__(self, txt_list,tokenizer, max_length, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.stride = stride\n",
        "\n",
        "        def tokenize_one_sample(txt):\n",
        "            token_ids = self.tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
        "            for i in range(0, len(token_ids) - self.max_length, self.stride):\n",
        "                input_chunk = token_ids[i:i + self.max_length]\n",
        "                target_chunk = token_ids[i + 1: i + self.max_length + 1]\n",
        "                self.input_ids.append(torch.tensor(input_chunk))\n",
        "                self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "        for txt in txt_list:\n",
        "            tokenize_one_sample(txt)\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]\n",
        "\n",
        "def LMDataloader(txt_list,batch_size, max_length, stride, shuffle = True, drop_list = True, num_workers = 0):\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "    dataset = LMDataset(txt_list,tokenizer, max_length, stride)\n",
        "\n",
        "    dataloader = DataLoader(dataset, batch_size = batch_size, shuffle = shuffle, drop_last = drop_list, num_workers = num_workers)\n",
        "    return dataloader\n",
        "\n",
        "def finalDataLoader(batch_size, max_length, stride, train_ratio = 0.8, shuffle = True, drop_list = True, num_workers = 0):\n",
        "    try:\n",
        "        formatted_dataset = json.load(open(r\"formatted_manim_scene_dataset.json\"))\n",
        "    except Exception as e:\n",
        "        print(f\"formatted_manim_scene_dataset.json not found with error:{e}\")\n",
        "        formatted_dataset = DataCreation().converting_to_continuous_Text()\n",
        "    print(\"formatted sample size: \", len(formatted_dataset))\n",
        "    DataCreation().save_formatted_data(formatted_dataset)\n",
        "\n",
        "\n",
        "    print(formatted_dataset[0])\n",
        "    print(len(formatted_dataset))\n",
        "    split_idx = int(train_ratio * len(formatted_dataset))\n",
        "    train_data = formatted_dataset[:split_idx]\n",
        "    val_data = formatted_dataset[split_idx:]\n",
        "    traindataloader = LMDataloader(\n",
        "        txt_list=train_data,\n",
        "        batch_size=batch_size,\n",
        "        max_length=max_length,\n",
        "        stride=stride\n",
        "    )\n",
        "    valdataloader = LMDataloader(\n",
        "        txt_list=val_data,\n",
        "        batch_size=batch_size,\n",
        "        max_length=max_length,\n",
        "        stride=stride\n",
        "    )\n",
        "    return traindataloader, valdataloader\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    batch_size = 8\n",
        "    max_length = 4\n",
        "    stride = 1\n",
        "\n",
        "    vocab_size = 50257\n",
        "    output_dim = 256\n",
        "    context_length = 1024\n",
        "\n",
        "    token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
        "    pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
        "\n",
        "    dataloader,_ = finalDataLoader(batch_size, max_length, stride)\n",
        "    print(type(dataloader))\n",
        "\n",
        "\n",
        "\n",
        "    for batch in dataloader:\n",
        "        x, y = batch\n",
        "\n",
        "        token_embeddings = token_embedding_layer(x)\n",
        "        pos_embeddings = pos_embedding_layer(torch.arange(max_length))\n",
        "\n",
        "        input_embeddings = token_embeddings + pos_embeddings\n",
        "\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "As43CC_OM_zG",
        "outputId": "1fbaaaa2-670e-4e9d-919b-1f464e306f5d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "formatted_manim_scene_dataset.json not found with error:[Errno 2] No such file or directory: 'formatted_manim_scene_dataset.json'\n",
            "formatted sample size:  644\n",
            "for visualization of the scene with description: A blue rectangle 2.4x1.3 units draws itselfand duration: 1-2 seconds, python and manim based code is the follwoing:\n",
            "from manim import *\n",
            "\n",
            "class Scene1(Scene):\n",
            "    def construct(self):\n",
            "        rect = Rectangle(width=2.4, height=1.3).set_color(BLUE)\n",
            "        self.play(ShowCreation(rect))\n",
            "        self.wait(1)\n",
            "644\n",
            "<class 'torch.utils.data.dataloader.DataLoader'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "# from untokenizeddataformation import finalDataLoader\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias = False):\n",
        "        super().__init__()\n",
        "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out,d_out)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        keys = self.W_key(x)\n",
        "        query = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = query.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        keys = keys.transpose(1,2)\n",
        "        queries = queries.transpose(1,2)\n",
        "        values = values.transpose(1,2)\n",
        "\n",
        "\n",
        "        attn_scores = queries @ keys.transpose(2,3)\n",
        "\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        context_vec = (attn_weights @ values).transpose(1,2)\n",
        "\n",
        "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec)\n",
        "        return context_vec\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     torch.manual_seed(123)\n",
        "#     batch_size = 8\n",
        "#     max_length = 4\n",
        "#     stride = 1\n",
        "\n",
        "#     vocab_size = 50257\n",
        "#     output_dim = 256\n",
        "#     context_length = 1024\n",
        "\n",
        "#     token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
        "#     pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
        "\n",
        "#     dataloader = finalDataLoader(batch_size, max_length, stride)\n",
        "\n",
        "#     for batch in dataloader:\n",
        "#         x, y = batch\n",
        "\n",
        "#         token_embeddings = token_embedding_layer(x)\n",
        "#         pos_embeddings = pos_embedding_layer(torch.arange(max_length))\n",
        "\n",
        "#         input_embeddings = token_embeddings + pos_embeddings\n",
        "\n",
        "#         break\n",
        "\n",
        "#     context_length = max_length\n",
        "#     d_in = output_dim\n",
        "#     d_out = d_in\n",
        "\n",
        "#     mha = MultiHeadAttention(d_in, d_out, context_length, 0.0, num_heads=2)\n",
        "\n",
        "#     batch = input_embeddings\n",
        "#     context_vecs = mha(batch)\n",
        "\n",
        "#     print(\"context_vecs.shape:\", context_vecs.shape)"
      ],
      "metadata": {
        "id": "rJUx0S4UNIZr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "# from multiheadattaention import *\n",
        "\n",
        "\n",
        "\n",
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    def forward(self,x):\n",
        "        return 0.5*x*(1+torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0/torch.pi)) * (x+0.044715 * torch.pow(x,3))\n",
        "        ))\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "            GELU(),\n",
        "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, embed_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(embed_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(embed_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim = True, unbiased = False)\n",
        "        norm_x = (x-mean)/ torch.sqrt(var + self.eps)\n",
        "        return self.scale * norm_x + self.shift\n",
        "\n",
        "\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"])\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)   # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class ManimGPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(\n",
        "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
        "        )\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     import tiktoken\n",
        "\n",
        "#     Manim_GPT_CONFIG= {\n",
        "#         \"vocab_size\": 50257,    # Vocabulary size\n",
        "#         \"context_length\": 1024, # Context length\n",
        "#         \"emb_dim\": 256,         # Embedding dimension\n",
        "#         \"n_heads\": 4,          # Number of attention heads\n",
        "#         \"n_layers\": 2,         # Number of layers\n",
        "#         \"drop_rate\": 0.20,       # Dropout rate\n",
        "#         \"qkv_bias\": False       # Query-Key-Value bias\n",
        "#     }\n",
        "\n",
        "\n",
        "#     tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "#     batch = []\n",
        "\n",
        "#     txt1 = \"Every effort moves you\"\n",
        "#     txt2 = \"Every day holds a\"\n",
        "\n",
        "#     batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
        "#     batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
        "#     batch = torch.stack(batch, dim=0)\n",
        "#     print(batch)\n",
        "\n",
        "#     model = ManimGPTModel(Manim_GPT_CONFIG)\n",
        "#     logits = model(batch)\n",
        "#     print(logits.shape)\n",
        "#     total_params = sum(p.numel() for p in model.parameters())\n",
        "#     print(f\"Total number of parameters: {total_params:,}\")"
      ],
      "metadata": {
        "id": "V2Y1q94yNjHB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "# from untokenizeddataformation import finalDataLoader\n",
        "# from multiheadattaention import *\n",
        "# from manimgpt import *\n",
        "import tiktoken\n",
        "\n",
        "\n",
        "Manim_GPT_CONFIG= {\n",
        "    \"vocab_size\": 50257,    # Vocabulary size\n",
        "    \"context_length\": 1024, # Context length\n",
        "    \"emb_dim\": 768,         # Embedding dimension\n",
        "    \"n_heads\": 4,          # Number of attention heads\n",
        "    \"n_layers\": 2,         # Number of layers\n",
        "    \"drop_rate\": 0.1,       # Dropout rate\n",
        "    \"qkv_bias\": False       # Query-Key-Value bias\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "    # idx is (B, T) array of indices in the current context\n",
        "    for _ in range(max_new_tokens):\n",
        "        print(f\"step number:{_}\")\n",
        "\n",
        "        # Crop current context if it exceeds the supported context size\n",
        "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
        "        # then only the last 5 tokens are used as context\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "\n",
        "        # Get the predictions\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "\n",
        "        # Focus only on the last time step\n",
        "        # (batch, n_token, vocab_size) becomes (batch, vocab_size)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # Get the idx of the vocab entry with the highest logits value\n",
        "        idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch, 1)\n",
        "\n",
        "        # Append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
        "\n",
        "    return idx\n",
        "\n",
        "\n",
        "def text_to_token_ids(text,tokenizer):\n",
        "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
        "    return encoded_tensor\n",
        "def token_ids_to_text(token_ids,tokenizer):\n",
        "    flat = token_ids.squeeze(0)\n",
        "    return tokenizer.decode(flat.tolist())\n",
        "\n",
        "\n",
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)\n",
        "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
        "    return loss\n",
        "\n",
        "\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        # Reduce the number of batches to match the total number of batches in the data loader\n",
        "        # if num_batches exceeds the number of batches in the data loader\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches\n",
        "\n",
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches = eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches = eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss\n",
        "\n",
        "\n",
        "def train_model(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                eval_freq, eval_iter):\n",
        "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "    tokens_seen, global_step = 0, -1\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad(optimizer)\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            tokens_seen += input_batch.numel()\n",
        "            global_step += 1\n",
        "\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, eval_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter\n",
        "                )\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(eval_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {eval_loss:.3f}\")\n",
        "    return train_losses, val_losses, track_tokens_seen\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = ManimGPTModel(Manim_GPT_CONFIG).to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.004, weight_decay=0.1)\n",
        "    batch_size = 20\n",
        "    max_length = 100\n",
        "    stride = 5\n",
        "    train_loader, val_loader = finalDataLoader(batch_size, max_length, stride)\n",
        "\n",
        "    num_epochs = 5\n",
        "    print(len(train_loader))\n",
        "\n",
        "    train_losses, val_losses, tokens_seen = train_model(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=5, eval_iter=5\n",
        "    )\n",
        "\n",
        "\n",
        "    torch.save(model.state_dict(), \"manimgpt.pt\")\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdoGD-l1OHxJ",
        "outputId": "4de814e7-899c-4911-fda0-f91f29fe856e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "formatted sample size:  644\n",
            "for visualization of the scene with description: A blue rectangle 2.4x1.3 units draws itselfand duration: 1-2 seconds, python and manim based code is the follwoing:\n",
            "from manim import *\n",
            "\n",
            "class Scene1(Scene):\n",
            "    def construct(self):\n",
            "        rect = Rectangle(width=2.4, height=1.3).set_color(BLUE)\n",
            "        self.play(ShowCreation(rect))\n",
            "        self.wait(1)\n",
            "644\n",
            "200\n",
            "Ep 1 (Step 000000): Train loss 5.695, Val loss 5.869\n",
            "Ep 1 (Step 000005): Train loss 3.753, Val loss 4.049\n",
            "Ep 1 (Step 000010): Train loss 3.223, Val loss 3.506\n",
            "Ep 1 (Step 000015): Train loss 2.896, Val loss 3.236\n",
            "Ep 1 (Step 000020): Train loss 2.549, Val loss 2.971\n",
            "Ep 1 (Step 000025): Train loss 2.216, Val loss 2.694\n",
            "Ep 1 (Step 000030): Train loss 1.897, Val loss 2.736\n",
            "Ep 1 (Step 000035): Train loss 1.590, Val loss 2.163\n",
            "Ep 1 (Step 000040): Train loss 1.378, Val loss 1.981\n",
            "Ep 1 (Step 000045): Train loss 1.262, Val loss 1.819\n",
            "Ep 1 (Step 000050): Train loss 1.025, Val loss 1.524\n",
            "Ep 1 (Step 000055): Train loss 0.919, Val loss 1.818\n",
            "Ep 1 (Step 000060): Train loss 0.865, Val loss 1.572\n",
            "Ep 1 (Step 000065): Train loss 0.816, Val loss 1.542\n",
            "Ep 1 (Step 000070): Train loss 0.823, Val loss 1.401\n",
            "Ep 1 (Step 000075): Train loss 0.727, Val loss 1.755\n",
            "Ep 1 (Step 000080): Train loss 0.684, Val loss 1.557\n",
            "Ep 1 (Step 000085): Train loss 0.645, Val loss 1.509\n",
            "Ep 1 (Step 000090): Train loss 0.678, Val loss 1.886\n",
            "Ep 1 (Step 000095): Train loss 0.789, Val loss 1.779\n",
            "Ep 1 (Step 000100): Train loss 0.739, Val loss 1.529\n",
            "Ep 1 (Step 000105): Train loss 0.706, Val loss 1.407\n",
            "Ep 1 (Step 000110): Train loss 0.682, Val loss 1.534\n",
            "Ep 1 (Step 000115): Train loss 0.618, Val loss 1.450\n",
            "Ep 1 (Step 000120): Train loss 0.699, Val loss 1.213\n",
            "Ep 1 (Step 000125): Train loss 0.617, Val loss 1.271\n",
            "Ep 1 (Step 000130): Train loss 0.617, Val loss 1.198\n",
            "Ep 1 (Step 000135): Train loss 0.580, Val loss 1.500\n",
            "Ep 1 (Step 000140): Train loss 0.595, Val loss 1.390\n",
            "Ep 1 (Step 000145): Train loss 0.538, Val loss 1.220\n",
            "Ep 1 (Step 000150): Train loss 0.541, Val loss 1.194\n",
            "Ep 1 (Step 000155): Train loss 0.579, Val loss 1.612\n",
            "Ep 1 (Step 000160): Train loss 0.543, Val loss 1.165\n",
            "Ep 1 (Step 000165): Train loss 0.552, Val loss 1.168\n",
            "Ep 1 (Step 000170): Train loss 0.577, Val loss 1.294\n",
            "Ep 1 (Step 000175): Train loss 0.520, Val loss 1.748\n",
            "Ep 1 (Step 000180): Train loss 0.537, Val loss 0.997\n",
            "Ep 1 (Step 000185): Train loss 0.535, Val loss 1.228\n",
            "Ep 1 (Step 000190): Train loss 0.516, Val loss 1.310\n",
            "Ep 1 (Step 000195): Train loss 0.533, Val loss 1.696\n",
            "Ep 2 (Step 000200): Train loss 0.601, Val loss 1.419\n",
            "Ep 2 (Step 000205): Train loss 0.477, Val loss 1.450\n",
            "Ep 2 (Step 000210): Train loss 0.519, Val loss 1.133\n",
            "Ep 2 (Step 000215): Train loss 0.577, Val loss 1.372\n",
            "Ep 2 (Step 000220): Train loss 0.527, Val loss 1.375\n",
            "Ep 2 (Step 000225): Train loss 0.570, Val loss 1.122\n",
            "Ep 2 (Step 000230): Train loss 0.490, Val loss 1.161\n",
            "Ep 2 (Step 000235): Train loss 0.528, Val loss 1.138\n",
            "Ep 2 (Step 000240): Train loss 0.553, Val loss 1.280\n",
            "Ep 2 (Step 000245): Train loss 0.493, Val loss 1.075\n",
            "Ep 2 (Step 000250): Train loss 0.487, Val loss 1.318\n",
            "Ep 2 (Step 000255): Train loss 0.570, Val loss 1.517\n",
            "Ep 2 (Step 000260): Train loss 0.524, Val loss 1.478\n",
            "Ep 2 (Step 000265): Train loss 0.521, Val loss 1.375\n",
            "Ep 2 (Step 000270): Train loss 0.507, Val loss 0.998\n",
            "Ep 2 (Step 000275): Train loss 0.520, Val loss 1.668\n",
            "Ep 2 (Step 000280): Train loss 0.455, Val loss 1.427\n",
            "Ep 2 (Step 000285): Train loss 0.491, Val loss 1.260\n",
            "Ep 2 (Step 000290): Train loss 0.537, Val loss 1.152\n",
            "Ep 2 (Step 000295): Train loss 0.480, Val loss 1.028\n",
            "Ep 2 (Step 000300): Train loss 0.530, Val loss 1.286\n",
            "Ep 2 (Step 000305): Train loss 0.541, Val loss 1.385\n",
            "Ep 2 (Step 000310): Train loss 0.519, Val loss 1.109\n",
            "Ep 2 (Step 000315): Train loss 0.526, Val loss 0.992\n",
            "Ep 2 (Step 000320): Train loss 0.531, Val loss 1.421\n",
            "Ep 2 (Step 000325): Train loss 0.613, Val loss 1.307\n",
            "Ep 2 (Step 000330): Train loss 0.605, Val loss 1.044\n",
            "Ep 2 (Step 000335): Train loss 0.500, Val loss 1.106\n",
            "Ep 2 (Step 000340): Train loss 0.527, Val loss 0.945\n",
            "Ep 2 (Step 000345): Train loss 0.470, Val loss 1.000\n",
            "Ep 2 (Step 000350): Train loss 0.456, Val loss 1.552\n",
            "Ep 2 (Step 000355): Train loss 0.492, Val loss 1.149\n",
            "Ep 2 (Step 000360): Train loss 0.528, Val loss 0.930\n",
            "Ep 2 (Step 000365): Train loss 0.448, Val loss 1.071\n",
            "Ep 2 (Step 000370): Train loss 0.498, Val loss 1.231\n",
            "Ep 2 (Step 000375): Train loss 0.493, Val loss 1.596\n",
            "Ep 2 (Step 000380): Train loss 0.444, Val loss 1.180\n",
            "Ep 2 (Step 000385): Train loss 0.496, Val loss 1.348\n",
            "Ep 2 (Step 000390): Train loss 0.565, Val loss 1.289\n",
            "Ep 2 (Step 000395): Train loss 0.564, Val loss 1.185\n",
            "Ep 3 (Step 000400): Train loss 0.457, Val loss 1.659\n",
            "Ep 3 (Step 000405): Train loss 0.590, Val loss 1.502\n",
            "Ep 3 (Step 000410): Train loss 0.510, Val loss 0.960\n",
            "Ep 3 (Step 000415): Train loss 0.461, Val loss 1.183\n",
            "Ep 3 (Step 000420): Train loss 0.527, Val loss 1.320\n",
            "Ep 3 (Step 000425): Train loss 0.547, Val loss 0.826\n",
            "Ep 3 (Step 000430): Train loss 0.570, Val loss 1.024\n",
            "Ep 3 (Step 000435): Train loss 0.495, Val loss 1.156\n",
            "Ep 3 (Step 000440): Train loss 0.499, Val loss 1.193\n",
            "Ep 3 (Step 000445): Train loss 0.521, Val loss 1.217\n",
            "Ep 3 (Step 000450): Train loss 0.477, Val loss 0.935\n",
            "Ep 3 (Step 000455): Train loss 0.511, Val loss 1.009\n",
            "Ep 3 (Step 000460): Train loss 0.518, Val loss 0.872\n",
            "Ep 3 (Step 000465): Train loss 0.486, Val loss 1.410\n",
            "Ep 3 (Step 000470): Train loss 0.537, Val loss 1.323\n",
            "Ep 3 (Step 000475): Train loss 0.512, Val loss 1.493\n",
            "Ep 3 (Step 000480): Train loss 0.529, Val loss 0.970\n",
            "Ep 3 (Step 000485): Train loss 0.517, Val loss 1.350\n",
            "Ep 3 (Step 000490): Train loss 0.421, Val loss 0.947\n",
            "Ep 3 (Step 000495): Train loss 0.512, Val loss 1.333\n",
            "Ep 3 (Step 000500): Train loss 0.474, Val loss 1.111\n",
            "Ep 3 (Step 000505): Train loss 0.442, Val loss 1.078\n",
            "Ep 3 (Step 000510): Train loss 0.511, Val loss 1.450\n",
            "Ep 3 (Step 000515): Train loss 0.446, Val loss 1.088\n",
            "Ep 3 (Step 000520): Train loss 0.466, Val loss 1.246\n",
            "Ep 3 (Step 000525): Train loss 0.472, Val loss 1.208\n",
            "Ep 3 (Step 000530): Train loss 0.476, Val loss 0.994\n",
            "Ep 3 (Step 000535): Train loss 0.455, Val loss 1.418\n",
            "Ep 3 (Step 000540): Train loss 0.404, Val loss 1.164\n",
            "Ep 3 (Step 000545): Train loss 0.455, Val loss 0.930\n",
            "Ep 3 (Step 000550): Train loss 0.408, Val loss 1.305\n",
            "Ep 3 (Step 000555): Train loss 0.425, Val loss 1.435\n",
            "Ep 3 (Step 000560): Train loss 0.412, Val loss 1.257\n",
            "Ep 3 (Step 000565): Train loss 0.447, Val loss 1.451\n",
            "Ep 3 (Step 000570): Train loss 0.464, Val loss 0.865\n",
            "Ep 3 (Step 000575): Train loss 0.423, Val loss 1.113\n",
            "Ep 3 (Step 000580): Train loss 0.544, Val loss 1.281\n",
            "Ep 3 (Step 000585): Train loss 0.446, Val loss 1.212\n",
            "Ep 3 (Step 000590): Train loss 0.447, Val loss 1.323\n",
            "Ep 3 (Step 000595): Train loss 0.405, Val loss 0.969\n",
            "Ep 4 (Step 000600): Train loss 0.429, Val loss 1.292\n",
            "Ep 4 (Step 000605): Train loss 0.450, Val loss 1.144\n",
            "Ep 4 (Step 000610): Train loss 0.451, Val loss 1.616\n",
            "Ep 4 (Step 000615): Train loss 0.469, Val loss 1.227\n",
            "Ep 4 (Step 000620): Train loss 0.490, Val loss 1.331\n",
            "Ep 4 (Step 000625): Train loss 0.430, Val loss 1.341\n",
            "Ep 4 (Step 000630): Train loss 0.429, Val loss 1.286\n",
            "Ep 4 (Step 000635): Train loss 0.414, Val loss 1.056\n",
            "Ep 4 (Step 000640): Train loss 0.421, Val loss 1.194\n",
            "Ep 4 (Step 000645): Train loss 0.372, Val loss 1.059\n",
            "Ep 4 (Step 000650): Train loss 0.353, Val loss 1.092\n",
            "Ep 4 (Step 000655): Train loss 0.363, Val loss 0.993\n",
            "Ep 4 (Step 000660): Train loss 0.389, Val loss 1.305\n",
            "Ep 4 (Step 000665): Train loss 0.384, Val loss 1.172\n",
            "Ep 4 (Step 000670): Train loss 0.413, Val loss 1.217\n",
            "Ep 4 (Step 000675): Train loss 0.405, Val loss 0.834\n",
            "Ep 4 (Step 000680): Train loss 0.396, Val loss 1.448\n",
            "Ep 4 (Step 000685): Train loss 0.398, Val loss 0.908\n",
            "Ep 4 (Step 000690): Train loss 0.364, Val loss 1.065\n",
            "Ep 4 (Step 000695): Train loss 0.367, Val loss 1.182\n",
            "Ep 4 (Step 000700): Train loss 0.380, Val loss 0.797\n",
            "Ep 4 (Step 000705): Train loss 0.371, Val loss 0.752\n",
            "Ep 4 (Step 000710): Train loss 0.410, Val loss 0.960\n",
            "Ep 4 (Step 000715): Train loss 0.345, Val loss 1.211\n",
            "Ep 4 (Step 000720): Train loss 0.359, Val loss 1.275\n",
            "Ep 4 (Step 000725): Train loss 0.395, Val loss 1.540\n",
            "Ep 4 (Step 000730): Train loss 0.416, Val loss 1.038\n",
            "Ep 4 (Step 000735): Train loss 0.427, Val loss 1.081\n",
            "Ep 4 (Step 000740): Train loss 0.390, Val loss 1.158\n",
            "Ep 4 (Step 000745): Train loss 0.372, Val loss 1.134\n",
            "Ep 4 (Step 000750): Train loss 0.403, Val loss 1.147\n",
            "Ep 4 (Step 000755): Train loss 0.370, Val loss 1.096\n",
            "Ep 4 (Step 000760): Train loss 0.375, Val loss 0.987\n",
            "Ep 4 (Step 000765): Train loss 0.363, Val loss 1.193\n",
            "Ep 4 (Step 000770): Train loss 0.380, Val loss 1.210\n",
            "Ep 4 (Step 000775): Train loss 0.373, Val loss 1.264\n",
            "Ep 4 (Step 000780): Train loss 0.403, Val loss 1.102\n",
            "Ep 4 (Step 000785): Train loss 0.386, Val loss 1.120\n",
            "Ep 4 (Step 000790): Train loss 0.366, Val loss 1.207\n",
            "Ep 4 (Step 000795): Train loss 0.425, Val loss 1.088\n",
            "Ep 5 (Step 000800): Train loss 0.335, Val loss 1.001\n",
            "Ep 5 (Step 000805): Train loss 0.358, Val loss 1.026\n",
            "Ep 5 (Step 000810): Train loss 0.375, Val loss 1.213\n",
            "Ep 5 (Step 000815): Train loss 0.365, Val loss 1.028\n",
            "Ep 5 (Step 000820): Train loss 0.421, Val loss 0.925\n",
            "Ep 5 (Step 000825): Train loss 0.439, Val loss 1.218\n",
            "Ep 5 (Step 000830): Train loss 0.405, Val loss 1.140\n",
            "Ep 5 (Step 000835): Train loss 0.427, Val loss 1.163\n",
            "Ep 5 (Step 000840): Train loss 0.407, Val loss 0.864\n",
            "Ep 5 (Step 000845): Train loss 0.427, Val loss 0.934\n",
            "Ep 5 (Step 000850): Train loss 0.393, Val loss 1.038\n",
            "Ep 5 (Step 000855): Train loss 0.390, Val loss 1.181\n",
            "Ep 5 (Step 000860): Train loss 0.381, Val loss 1.078\n",
            "Ep 5 (Step 000865): Train loss 0.445, Val loss 1.004\n",
            "Ep 5 (Step 000870): Train loss 0.459, Val loss 1.169\n",
            "Ep 5 (Step 000875): Train loss 0.447, Val loss 0.892\n",
            "Ep 5 (Step 000880): Train loss 0.396, Val loss 0.971\n",
            "Ep 5 (Step 000885): Train loss 0.418, Val loss 1.082\n",
            "Ep 5 (Step 000890): Train loss 0.421, Val loss 1.005\n",
            "Ep 5 (Step 000895): Train loss 0.396, Val loss 1.132\n",
            "Ep 5 (Step 000900): Train loss 0.425, Val loss 1.429\n",
            "Ep 5 (Step 000905): Train loss 0.399, Val loss 1.395\n",
            "Ep 5 (Step 000910): Train loss 0.433, Val loss 1.259\n",
            "Ep 5 (Step 000915): Train loss 0.430, Val loss 1.406\n",
            "Ep 5 (Step 000920): Train loss 0.399, Val loss 1.450\n",
            "Ep 5 (Step 000925): Train loss 0.457, Val loss 1.184\n",
            "Ep 5 (Step 000930): Train loss 0.434, Val loss 1.139\n",
            "Ep 5 (Step 000935): Train loss 0.425, Val loss 1.203\n",
            "Ep 5 (Step 000940): Train loss 0.396, Val loss 1.045\n",
            "Ep 5 (Step 000945): Train loss 0.386, Val loss 1.027\n",
            "Ep 5 (Step 000950): Train loss 0.405, Val loss 1.273\n",
            "Ep 5 (Step 000955): Train loss 0.423, Val loss 1.002\n",
            "Ep 5 (Step 000960): Train loss 0.385, Val loss 1.025\n",
            "Ep 5 (Step 000965): Train loss 0.355, Val loss 0.941\n",
            "Ep 5 (Step 000970): Train loss 0.362, Val loss 1.032\n",
            "Ep 5 (Step 000975): Train loss 0.432, Val loss 1.305\n",
            "Ep 5 (Step 000980): Train loss 0.417, Val loss 1.203\n",
            "Ep 5 (Step 000985): Train loss 0.424, Val loss 1.213\n",
            "Ep 5 (Step 000990): Train loss 0.375, Val loss 1.260\n",
            "Ep 5 (Step 000995): Train loss 0.391, Val loss 1.221\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"checking inference\")\n",
        "model.to(\"cpu\")\n",
        "model.eval()\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(\"for visualization of the scene with description: A purple square morphs into triangleand duration: 2 seconds, python and manim based code is the follwoing:\", tokenizer),\n",
        "    max_new_tokens=1000,\n",
        "    context_size=Manim_GPT_CONFIG[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_s748TggPUnv",
        "outputId": "1ea9f49a-530d-4308-ffc9-c901f841a84d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checking inference\n"
          ]
        }
      ]
    }
  ]
}